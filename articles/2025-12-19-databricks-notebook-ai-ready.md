---
title: "Databricks Notebook é–‹ç™ºç’°å¢ƒã‚’ AI-Ready ã«ã™ã‚‹"
emoji: "ğŸ¤–"
type: "tech"
topics:
  - "databricks"
  - "jupyter"
  - "mise"
  - "precommit"
  - "uv"
publication_name: "genda_jp"
published: true
---

æ ªå¼ä¼šç¤¾GENDA ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ / MLOps ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã® uma-chan ã§ã™ã€‚
ã“ã®è¨˜äº‹ã¯ Databricks Advent Calendar 2025 ã‚·ãƒªãƒ¼ã‚º1 Day 19 ã®è¨˜äº‹ã§ã™ã€‚

@[card](https://qiita.com/advent-calendar/2025/databricks)

ãªã‚‰ã³ã« GENDA Advent Calendar 2025 ã‚·ãƒªãƒ¼ã‚º4 Day 19 ã®è¨˜äº‹ã§ã™ã€‚

@[card](https://qiita.com/advent-calendar/2025/genda)

æœ¬è¨˜äº‹ã¯ 2025-12-12 ã«é–‹å‚¬ã•ã‚ŒãŸ Databricks æ‹›å¾…ã‚¤ãƒ™ãƒ³ãƒˆ Data+AI World Tour Tokyo After Party ã§ã®ç™»å£‡å†…å®¹ã‚’å†æ§‹æˆã—ãŸã‚‚ã®ã§ã™ã€‚

<!-- rumdl-disable MD057 -->
@[speakerdeck](58be33da57d84a5eb9914aa8a8c903ec)
<!-- rumdl-enable MD057 -->

## 1. ã¯ã˜ã‚ã«

Databricks Notebook ã¯æ‰‹è»½ã«ãƒ‡ãƒ¼ã‚¿åˆ†æã‚„æ©Ÿæ¢°å­¦ç¿’ã®ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ”ãƒ³ã‚°ãŒã§ãã‚‹ä¾¿åˆ©ãªãƒ„ãƒ¼ãƒ«ã§ã™ãŒã€é–‹ç™ºä½“é¨“ã«ã¯ã„ãã¤ã‹ã®èª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚

ã•ã‚‰ã« Claude Code ã‚„ Cursor ãªã©ã® AI ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒæ™®åŠã—ãŸç¾åœ¨ã€ã“ã‚Œã‚‰ã®ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã—ã‚„ã™ã„çŠ¶æ…‹ã‚’ç›®æŒ‡ã™ã“ã¨ãŒé‡è¦ã¨ãªã£ã¦ã„ã¾ã™ã€‚

ä»¥ä¸‹ã§ Databricks Notebook é–‹ç™ºã‚’ AI-Ready ã«ã™ã‚‹ãŸã‚ã®4ã¤ã®æ”¹å–„ç­–ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## 2. èª²é¡Œæèµ·

### 2.1. å¾“æ¥ã® Databricks Notebook é–‹ç™ºã®èª²é¡Œ

Databricks Notebook ã‚’ãã®ã¾ã¾ä½¿ã£ãŸé–‹ç™ºã«ã¯ã€ä»¥ä¸‹ã®ã‚ˆã†ãªèª²é¡ŒãŒã‚ã‚Šã¾ã™ã€‚

1. ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã¨ã®ä¹–é›¢
   - Databricks ä¸Šã§ã—ã‹ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã§ããªã„
   - ä½¿ã„æ…£ã‚ŒãŸ VS Code ãªã©ã®ã‚¨ãƒ‡ã‚£ã‚¿ãŒä½¿ãˆãªã„
   - Git ã¨ã®é€£æºãŒç…©é›‘
2. ã‚³ãƒ¼ãƒ‰å“è³ªç®¡ç†ã®é›£ã—ã•
   - Linter / Formatter ã®é©ç”¨ãŒé›£ã—ã„
   - ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ã®ç®¡ç†ãŒè¤‡é›‘
   - ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒã—ã¥ã‚‰ã„
3. ä¾å­˜é–¢ä¿‚ç®¡ç†ã®è¤‡é›‘ã•
   - ä¾å­˜é–¢ä¿‚ã‚’è§£æ¶ˆã—ãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®šã™ã‚‹ã“ã¨ã®é›£æ˜“åº¦ã¯æƒ³åƒä»¥ä¸Šã«é«˜ãã€çªç„¶å‹•ã‹ãªããªã‚‹ãƒªã‚¹ã‚¯ãŒã‚ã‚‹

### 2.2. AI æ™‚ä»£ã®æ–°ãŸãªèª²é¡Œ

Claude Code ã‚„ Cursor ãªã©ã® AI ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒç™»å ´ã—ã€é–‹ç™ºç”Ÿç”£æ€§ãŒå¤§ããå‘ä¸Šã—ã¾ã—ãŸãŒã€Databricks Notebook ç’°å¢ƒã§ã¯ AI ãƒ„ãƒ¼ãƒ«ã®æ©æµã‚’å—ã‘ã«ãã„çŠ¶æ³ãŒã‚ã‚Šã¾ã™ã€‚

ãƒ­ãƒ¼ã‚«ãƒ«ã® AI ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ Databricks ä¸Šã®ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã™ã‚‹æ—¢å­˜ã®æ–¹æ³• (Databricks Connectã€VS Code æ‹¡å¼µãªã©) ã«ã¯ã€ãã‚Œãã‚Œåˆ¶ç´„ãŒã‚ã‚Šã¾ã™ã€‚è©³ç´°ã¯æ”¹å–„ç­–1ã§èª¬æ˜ã—ã¾ã™ã€‚

## 3. æ”¹å–„ç­–1: jupyter-databricks-kernel

### 3.1. æ¦‚è¦

ã¾ãšç´¹ä»‹ã™ã‚‹ã®ã¯ã€ç§ãŒé–‹ç™ºã—ãŸ `jupyter-databricks-kernel` ã§ã™ã€‚

@[card](https://github.com/i9wa4/jupyter-databricks-kernel)

Jupyter ã«ãŠã‘ã‚‹ã‚«ãƒ¼ãƒãƒ«ã¨ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ã‚»ãƒ«ã‚’å‡¦ç†ã—ã€çµæœã‚’ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ (VS Code ã‚„ JupyterLab ãªã©) ã«é€ä¿¡ã™ã‚‹ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã§ã™ã€‚

`jupyter-databricks-kernel` ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«ã® Jupyter ç’°å¢ƒã‹ã‚‰ Databricks Compute (all-purpose) ã«æ¥ç¶šã§ãã‚‹ã‚«ãƒ¼ãƒãƒ«ã‚’æä¾›ã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ä»¥ä¸‹ã®ã‚ˆã†ãªã‚³ãƒãƒ³ãƒ‰ã§ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã§ãã¾ã™ã€‚

```sh
jupyter execute notebook.ipynb --kernel_name=databricks --inplace
```

### 3.2. æ—¢å­˜ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã¨ã®é•ã„

Databricks ã§ã®ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã«ã¯ã€å…¬å¼ã® VS Code æ‹¡å¼µ (Databricks Connect Integration) ã¨ã„ã†ã‚¢ãƒ—ãƒ­ãƒ¼ãƒãŒã‚ã‚Šã¾ã™ã€‚

[å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.databricks.com/aws/en/dev-tools/vscode-ext/notebooks) ã«ã‚ˆã‚‹ã¨ã€VS Code æ‹¡å¼µã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å®Ÿè¡Œã¯ Databricks Connect ã‚’ä½¿ç”¨ã—ã¦ãŠã‚Šã€ä»¥ä¸‹ã®ã‚ˆã†ã«å‹•ä½œã—ã¾ã™ã€‚

> All code runs locally, while all code involving DataFrame operations runs on the cluster in the remote Databricks workspace and run responses are sent back to the local caller.

ã¤ã¾ã‚Šã€é€šå¸¸ã® Python ã‚³ãƒ¼ãƒ‰ã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œã•ã‚Œã€DataFrame æ“ä½œã®ã¿ãŒãƒªãƒ¢ãƒ¼ãƒˆã‚¯ãƒ©ã‚¹ã‚¿ã§å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚

| è¦³ç‚¹                 | VS Code æ‹¡å¼µ (Databricks Connect)    | jupyter-databricks-kernel   |
| -------------------- | ---------------------------------    | --------------------------- |
| å®Ÿè¡Œå ´æ‰€             | ãƒ­ãƒ¼ã‚«ãƒ« + ãƒªãƒ¢ãƒ¼ãƒˆ (DataFrame ã®ã¿) | Databricks ä¸Š               |
| å®Ÿè¡Œçµæœã®å–å¾—       | â—‹                                   | â—‹                          |
| AI ãƒ„ãƒ¼ãƒ«ã‹ã‚‰ã®å®Ÿè¡Œ  | Ã—                                   | â—‹                          |
| DBR ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | ãƒ­ãƒ¼ã‚«ãƒ«ã«ã‚‚è¦ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«           | ãã®ã¾ã¾åˆ©ç”¨å¯èƒ½            |

`jupyter-databricks-kernel` ã¯ã™ã¹ã¦ã®ã‚³ãƒ¼ãƒ‰ã‚’ Databricks ä¸Šã§å®Ÿè¡Œã™ã‚‹ãŸã‚ã€Databricks Runtime ã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚ŒãŸãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ãã®ã¾ã¾åˆ©ç”¨ã§ãã€ä»»æ„ã®ã‚¨ãƒ‡ã‚£ã‚¿ã‚„ AI ãƒ„ãƒ¼ãƒ«ã‹ã‚‰å®Ÿè¡Œçµæœã‚’å–å¾—ã§ãã¾ã™ã€‚

### 3.3. ãƒ¡ãƒªãƒƒãƒˆ

- æ—¢å­˜ã®ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã®ãƒ•ãƒ«æ´»ç”¨
    - VS Code + Jupyter æ‹¡å¼µã§å¿«é©ãªé–‹ç™ºä½“é¨“
    - ä½¿ã„æ…£ã‚ŒãŸã‚¨ãƒ‡ã‚£ã‚¿ã®æ©Ÿèƒ½ã‚’ãƒ•ãƒ«æ´»ç”¨
- AI ãƒ„ãƒ¼ãƒ«ã¨ã®é€£æºãŒå®¹æ˜“
    - `jupyter execute` ã‚³ãƒãƒ³ãƒ‰ã§ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’å®Ÿè¡Œã—ã€çµæœã‚’å–å¾—ã§ãã‚‹
    - AI ãŒå®Ÿè¡Œçµæœã‚’è¦‹ã¦æ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’åˆ¤æ–­ã§ãã‚‹ãŸã‚ã€è‡ªå¾‹çš„ãªè©¦è¡ŒéŒ¯èª¤ãŒå¯èƒ½
    - ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã‹ã‚‰ç‹¬ç«‹ã—ã¦ã„ã‚‹ãŸã‚ã€å¤§è¦æ¨¡ DataFrame ã®å‡¦ç†ãªã©ã‚¯ãƒ©ã‚¹ã‚¿ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æ°—å…¼ã­ãªãåˆ©ç”¨ã§ãã‚‹

### 3.4. ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ

- åˆ©ç”¨ã—ã¦ã„ã‚‹ API ã®åˆ¶ç´„ä¸Š Serverless Compute ã«ã¯å¯¾å¿œã—ã¦ã„ãªã„

### 3.5. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

```mermaid
graph TB
    subgraph Local["ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒ"]
        subgraph Client["ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"]
            A["VS Code + Jupyter"]
            B["Claude Code"]
        end
        A --> C["jupyter-databricks-kernel"]
        B --> C
    end

    C -->|Databricks SDK| D

    subgraph Databricks["Databricks Workspace"]
        D["Databricks Compute"]
    end
```

## 4. æ”¹å–„ç­–2: Skinny Notebook Wrapper + Pure Python

### 4.1. åŸºæœ¬çš„ãªè€ƒãˆæ–¹

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä¾¿åˆ©ã§ã™ãŒã€ãƒ­ã‚¸ãƒƒã‚¯ã‚’ã™ã¹ã¦ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«æ›¸ãã¨ç®¡ç†ãŒé›£ã—ããªã‚Šã¾ã™ã€‚ãã“ã§æ¨å¥¨ã™ã‚‹ã®ãŒ "Skinny Notebook Wrapper + Pure Python" (ã„ãšã‚Œã‚‚é€ èª) ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚

Web é–‹ç™ºã«ãŠã‘ã‚‹ "Skinny Controller, Fat Model" (ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¯å‡¦ç†ã‚’æŒ¯ã‚Šåˆ†ã‘ã‚‹ã ã‘ã§ã€ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¯ãƒ¢ãƒ‡ãƒ«å±¤ã«æ›¸ãè¨­è¨ˆ) ã¨åŒã˜è€ƒãˆæ–¹ã§ã™ã€‚

- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Œè–„ã„ãƒ©ãƒƒãƒ‘ãƒ¼ã€ã¨ã—ã¦ä½¿ã„ç¶šã‘ã‚‹
- ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ã¯ `.py` ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ‡ã‚Šå‡ºã™
- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰ã¯ `.py` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‘¼ã³å‡ºã™ã ã‘

### 4.2. ãªãœãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æ®‹ã™ã®ã‹

ãƒ­ã‚¸ãƒƒã‚¯ã‚’ `.py` ã«åˆ‡ã‚Šå‡ºã—ã¦ã‚‚ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä»¥ä¸‹ã®ç†ç”±ã§ä¾¿åˆ©ã§ã™ã€‚

| å½¹å‰²                                 | ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯  | .py ãƒ•ã‚¡ã‚¤ãƒ«  |
| ------                               | ------------- | ------------- |
| ãƒã‚¸ãƒƒã‚¯ã‚³ãƒãƒ³ãƒ‰ (%pip install ç­‰)   | â—‹            | Ã—            |
| dbutils.widgets ã«ã‚ˆã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾© | â—‹            | Ã—            |
| ãƒ†ã‚¹ãƒˆã®æ›¸ãã‚„ã™ã•                   | Ã—            | â—‹            |
| AI ãƒ„ãƒ¼ãƒ«ã¨ã®è¦ªå’Œæ€§                  | â–³            | â—‹            |

ã¤ã¾ã‚Šã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ŒJob ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€ã¨ã—ã¦æ®‹ã—ã¤ã¤ã€ãƒ­ã‚¸ãƒƒã‚¯ã¯ `.py` ã«æ›¸ãã®ãŒãƒ™ã‚¹ãƒˆã§ã™ã€‚

### 4.3. æ§‹æˆä¾‹

```text
project/
â”œâ”€â”€ launcher.py       # è–„ã„ãƒ©ãƒƒãƒ‘ãƒ¼(Sourceå½¢å¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯)
â”œâ”€â”€ main.py           # ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯(é€šå¸¸ã® Python ãƒ•ã‚¡ã‚¤ãƒ«)
â”œâ”€â”€ test_main.py      # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
â””â”€â”€ pyproject.toml    # uv, Ruff è¨­å®šç­‰
```

ã“ã“ã¾ã§æ•´ç†ã™ã‚‹ã¨éå¸¸ã«ã™ã£ãã‚Šã—ã¾ã™ãŒã€é›‘ã« .py ã«åˆ‡ã‚Šå‡ºã—ã¦é›‘ã«å‘¼ã³å‡ºã™ã ã‘ã§ã‚‚å¤§ããåŠ¹æœã‚’å¾—ã‚‰ã‚Œã¾ã™ã€‚

### 4.4. launcher (ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯) ã®ä¾‹

<!-- rumdl-disable MD036 -->
**Cell 1: Widget å®šç¾©**
<!-- rumdl-enable MD036 -->

`dbutils.widgets.text()` ã§ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’å®šç¾©ã—ã¾ã™ã€‚

```python
dbutils.widgets.text("table_name", "samples.nyctaxi.trips", "Table Name")
dbutils.widgets.text("limit", "10", "Limit")
```

<!-- rumdl-disable MD036 -->
**Cell 2: main() å®Ÿè¡Œ**
<!-- rumdl-enable MD036 -->

Widget ã§å®šç¾©ã—ãŸãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ãƒ­ã‚¸ãƒƒã‚¯(`main.py`)ã«æ¸¡ã—ã¾ã™ã€‚

```python
from main import main

main(
    table_name=dbutils.widgets.get("table_name"),
    limit=int(dbutils.widgets.get("limit")),
)
```

ãƒã‚¤ãƒ³ãƒˆ

- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Œèµ·å‹•è£…ç½®ã€ã«å¾¹ã™ã‚‹
- `dbutils` ã¯ Databricks Compute ã§ã¯äº‹å‰å®šç¾©ã•ã‚Œã¦ã„ã‚‹ã®ã§ Notebook å†…ã§ä½¿ã„åˆ‡ã£ã¦ãŠã
    - .py ãƒ•ã‚¡ã‚¤ãƒ«ã« `dbutils` ã‚’æ›¸ã‹ãªã„ã“ã¨ã§æœªå®šç¾©ã‚¨ãƒ©ãƒ¼ã‚’åŠ¹ã‹ã›ã‚‹ã“ã¨ãŒã§ãã‚‹

### 4.5. main.py ã«ãƒ­ã‚¸ãƒƒã‚¯ã‚’é›†ç´„

```python
"""ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

from pyspark.sql import DataFrame, SparkSession


def load_table(spark: SparkSession, table_name: str, limit: int) -> DataFrame:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    return spark.table(table_name).limit(limit)


def main(table_name: str, limit: int = 10) -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†(ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰å‘¼ã°ã‚Œã‚‹)"""
    spark = SparkSession.builder.getOrCreate()
    df = load_table(spark, table_name, limit)
    df.show()
```

ãƒã‚¤ãƒ³ãƒˆ

- `load_table()` ã¯ `spark` ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ãŸã‚ãƒ¢ãƒƒã‚¯å¯èƒ½
- `dbutils` ã«ä¾å­˜ã—ãªã„
- å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã§ IDE è£œå®ŒãŒåŠ¹ã

### 4.6. ãƒ†ã‚¹ãƒˆã®ä¾‹

`load_table()` ã¯ `spark` ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ãŸã‚ã€ãƒ¢ãƒƒã‚¯ã‚’ä½¿ã£ã¦ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚

```python
# test_main.py
from unittest.mock import MagicMock

from main import load_table


def test_load_table():
    mock_spark = MagicMock()
    mock_df = MagicMock()
    mock_spark.table.return_value.limit.return_value = mock_df

    result = load_table(mock_spark, "test_table", 10)

    mock_spark.table.assert_called_once_with("test_table")
    mock_spark.table.return_value.limit.assert_called_once_with(10)
    assert result == mock_df
```

ã“ã®ãƒ†ã‚¹ãƒˆã¯ Databricks ç’°å¢ƒãŒãªãã¦ã‚‚å®Ÿè¡Œã§ãã¾ã™ã€‚

```bash
pytest test_main.py
```

### 4.7. ãƒ¡ãƒªãƒƒãƒˆ

1. ã‚³ãƒ¼ãƒ‰å“è³ªã®å‘ä¸Š
   - Pure Python ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯ Linter / Formatter ãŒé©ç”¨ã—ã‚„ã™ã„
   - é™çš„è§£æãƒ„ãƒ¼ãƒ«(mypy ãªã©)ã‚‚æ´»ç”¨å¯èƒ½

2. ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£ã®å‘ä¸Š
   - pytest ãªã©ã®æ¨™æº–çš„ãªãƒ†ã‚¹ãƒˆãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ãŒä½¿ãˆã‚‹
   - ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆãŒæ›¸ãã‚„ã™ã„

3. AI ãƒ„ãƒ¼ãƒ«ã¨ã®è¦ªå’Œæ€§
   - Pure Python ãƒ•ã‚¡ã‚¤ãƒ«ã¯ AI ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒç†è§£ã—ã‚„ã™ã„
   - ã‚³ãƒ¼ãƒ‰è£œå®Œã®ç²¾åº¦ãŒå‘ä¸Š
   - ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ææ¡ˆã‚‚å—ã‘ã‚„ã™ã„

4. ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®åŠ¹ç‡åŒ–
   - `.py` ãƒ•ã‚¡ã‚¤ãƒ«ã¯å·®åˆ†ãŒè¦‹ã‚„ã™ã„
   - PR ã§ã®ãƒ¬ãƒ“ãƒ¥ãƒ¼ãŒå®¹æ˜“

## 5. æ”¹å–„ç­–3: uv ã«ã‚ˆã‚‹ä¾å­˜é–¢ä¿‚ç®¡ç†

### 5.1. uv ã¨ã¯

uv ã¯ Rust è£½ã®é«˜é€Ÿãª Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ã§ã™ã€‚

@[card](https://docs.astral.sh/uv/)

ä¸»ãªç‰¹å¾´

- pip ã® 10-100 å€é«˜é€Ÿ
- `uv.lock` ã«ã‚ˆã‚‹å†ç¾å¯èƒ½ãªä¾å­˜é–¢ä¿‚ç®¡ç†
- Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚‚å¯èƒ½

### 5.2. uv sync --active

`--active` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã†ã¨ã€Databricks ã®æ—¢å­˜ç’°å¢ƒã«ç›´æ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

```python
%pip install uv
```

```python
import subprocess

result = subprocess.run(
    ["uv", "sync", "--no-dev", "--active"],
    capture_output=True,
    text=True
)
```

`--active` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã€æ–°ã—ã„ `.venv` ã‚’ä½œæˆã›ãšã€ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªä»®æƒ³ç’°å¢ƒã‚’ä½¿ç”¨ã—ã¾ã™ã€‚
Databricks ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç’°å¢ƒã§ã¯æ—¢ã«ä»®æƒ³ç’°å¢ƒãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ã¦ã„ã‚‹ã®ã§ã“ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã†ã¨ã„ã†ã‚ã‘ã§ã™ã€‚

### 5.3. pyproject.toml ã®æ§‹æˆä¾‹

```toml:pyproject.toml
[project]
name = "databricks-project"
version = "0.1.0"
requires-python = ">=3.12"
dependencies = [
    # Project-specific (not included in DBR)
    "httpx",
]

[project.optional-dependencies]
dbr-17-3 = [
    # DBR 17.3 LTS preinstalled packages
    # https://docs.databricks.com/aws/en/release-notes/runtime/17.3lts
    #
    # Purpose:
    # - Used for dependency resolution in uv.lock (not installed by uv sync)
    # - Ensures compatibility with Databricks Runtime environment
    # - Excluded from Renovate updates via matchDepTypes in renovate.json
    "matplotlib==3.10.0",
    "mlflow-skinny==3.0.1",
    "numpy==2.1.3",
    "pandas==2.2.3",
    "pyarrow==19.0.1",
    "pyspark==4.0.0",
    "scikit-learn==1.6.1",
    "scipy==1.15.1",
]

[dependency-groups]
dev = [
    "jupyter-databricks-kernel",
    "jupyterlab",
    "pytest",
    "ruff",
]
```

ãƒã‚¤ãƒ³ãƒˆ

- `dependencies`: Databricks ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ (Databricks Runtime ã«ãªã„ã‚‚ã®)
- `[project.optional-dependencies]`: Databricks Runtime ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
    - `uv sync` ã§ã¯ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œãªã„ (ä¾å­˜è§£æ±ºã®ã¿ã«ä½¿ç”¨)
    - Databricks Runtime ã¨ã®äº’æ›æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã«ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å›ºå®š
    - Databricks å´ã‹ã‚‰ requirements.txt ãŒæä¾›ã•ã‚Œã¦ãªã•ãã†ãªã®ã§ãƒªãƒªãƒ¼ã‚¹ãƒãƒ¼ãƒˆã‹ã‚‰æƒ…å ±ã‚’å–å¾—ã—ã¾ã—ãŸ
- `dev`: ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºãƒ„ãƒ¼ãƒ«

### 5.4. Renovate ã§ Databricks Runtime ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’æ›´æ–°å¯¾è±¡ã‹ã‚‰é™¤å¤–

å¾Œè¿°ã™ã‚‹ Renovate ã¨ã®ç›¸æ€§ã‚’è€ƒæ…®ã—ã¦ãŠãã¾ã™ã€‚
Databricks Runtime ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ Databricks Runtime ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã¦å›ºå®šã™ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ã€Renovate ã®è‡ªå‹•æ›´æ–°ã‹ã‚‰é™¤å¤–ã—ã¾ã™ã€‚

```json:renovate.json
{
  "$schema": "https://docs.renovatebot.com/renovate-schema.json",
  "extends": ["config:recommended"],
  "packageRules": [
    {
      "matchDepTypes": ["optional-dependencies"],
      "enabled": false
    }
  ]
}
```

### 5.5. ãƒ¡ãƒªãƒƒãƒˆ

1. é«˜é€Ÿãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
   - `pip` ã® 10-100 å€é«˜é€Ÿ
2. å³å¯†ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
   - `uv.lock` ã«ã‚ˆã‚‹å®Œå…¨ãªãƒãƒ¼ã‚¸ãƒ§ãƒ³å›ºå®š
   - å†ç¾æ€§ã®ç¢ºä¿
3. ãƒ­ãƒ¼ã‚«ãƒ«ã¨ Databricks ã§ã®çµ±ä¸€
   - åŒã˜ `pyproject.toml` / `uv.lock` ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã¨ Databricks ã§ä½¿ç”¨
   - ç’°å¢ƒå·®ç•°ã«ã‚ˆã‚‹ãƒã‚°ã‚’é˜²æ­¢

## 6. æ”¹å–„ç­–4: ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«

### 6.1. ãªãœã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ãŒå¿…è¦ã‹

AI ãƒ„ãƒ¼ãƒ«ã‚’æ´»ç”¨ã™ã‚‹ä¸Šã§é‡è¦ãªã®ãŒã€Œã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã€ã§ã™ã€‚AI ãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã«ã‚‚ã€äººé–“ãŒæ›¸ã„ãŸã‚³ãƒ¼ãƒ‰ã¨åŒã˜å“è³ªãƒã‚§ãƒƒã‚¯ã‚’é©ç”¨ã™ã‚‹ã“ã¨ã§ã€ã‚³ãƒ¼ãƒ‰å“è³ªã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚’æ‹…ä¿ã—ã¾ã™ã€‚

ã‚¯ãƒ©ã‚¦ãƒ‰ IDE ã‹ã‚‰ã‚³ãƒŸãƒƒãƒˆã—ãŸã‚Š AI ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãŒç›´æ¥ PR ã‚’ä½œæˆã™ã‚‹ã‚±ãƒ¼ã‚¹ãŒå¢—ãˆã¦ã„ã‚‹ã®ã§å¯¾å¿œã—ã¦ãŠãã¨å®‰å¿ƒã§ã™ã€‚

### 6.2. æ¨å¥¨ãƒ„ãƒ¼ãƒ«ã‚¹ã‚¿ãƒƒã‚¯

```mermaid
flowchart TB
    subgraph è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        F[mise.toml]
        G[.pre-commit-config.yaml]
    end

    è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« --> ãƒ­ãƒ¼ã‚«ãƒ« & CI

    subgraph ãƒ­ãƒ¼ã‚«ãƒ«
        L[pre-commit hook]
    end

    AI[AI ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ] -->|PR| CI
    L -->|PR| CI

    subgraph CI[GitHub Actions]
        D[pre-commit run]
    end

    CI --> P[ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«]
    P -->|ãƒãƒ¼ã‚¸| M[main]

    E[Renovate] -.->|è‡ªå‹•æ›´æ–°| è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
```

1. **mise** (ãƒ©ãƒ³ã‚¿ã‚¤ãƒ ç®¡ç†)
   - ãƒ„ãƒ¼ãƒ«ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã§ä¸€å…ƒç®¡ç†
   - ãƒãƒ¼ãƒ å…¨ä½“ã§çµ±ä¸€ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ³
2. **pre-commit** (ã‚³ãƒŸãƒƒãƒˆæ™‚ãƒã‚§ãƒƒã‚¯)
   - ãƒ­ãƒ¼ã‚«ãƒ«ã§ã‚‚ GitHub Actions ã§ã‚‚åŒã˜ãƒã‚§ãƒƒã‚¯ã‚’å®Ÿè¡Œ
   - Linter / Formatter ã®è‡ªå‹•å®Ÿè¡Œ
   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¹ã‚­ãƒ£ãƒ³
3. **Renovate** (ä¾å­˜é–¢ä¿‚ã®è‡ªå‹•æ›´æ–°)
   - mise.tomlã€pre-commitã€GitHub Actions ã§ä½¿ç”¨ã™ã‚‹ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’ç¶™ç¶šçš„ã«æ›´æ–°
   - ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ‘ãƒƒãƒã®è‡ªå‹•é©ç”¨
4. **ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«** (æœ€å¾Œã®ç ¦)
   - ç›´æ¥ push ã‚„ force push ã‚’é˜²æ­¢

### 6.3. mise.toml ã®ä¾‹

```toml:mise.toml
[tools]
uv = "0.9.15"
pre-commit = "4.5.0"
shellcheck = "0.11.0"
"aqua:rhysd/actionlint" = "1.7.9"
"aqua:gitleaks/gitleaks" = "8.30.0"
```

mise ã§ uv è‡ªä½“ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’ç®¡ç†ã—ã€uv ã§ Python ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ç®¡ç†ã™ã‚‹çµ„ã¿åˆã‚ã›ãŒãŠã™ã™ã‚ã§ã™ã€‚

### 6.4. pre-commit è¨­å®šä¾‹

`repo: local` + `mise exec --` ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ã†ã¨ã€mise ã§ç®¡ç†ã•ã‚ŒãŸãƒ„ãƒ¼ãƒ«ã‚’ hook ã¨ã—ã¦ä½¿ãˆã¾ã™ã€‚

```yaml:.pre-commit-config.yaml
default_stages: [pre-commit]
repos:
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v6.0.0
    hooks:
      - id: check-json
      - id: check-yaml
      - id: detect-private-key
      - id: end-of-file-fixer
      - id: trailing-whitespace

  - repo: local
    hooks:
      - id: gitleaks
        name: Detect hardcoded secrets
        entry: mise exec -- gitleaks protect --verbose --redact --staged
        language: system
        pass_filenames: false

      - id: gitleaks-history
        name: Detect hardcoded secrets (history)
        entry: mise exec -- gitleaks detect --verbose --redact
        language: system
        pass_filenames: false
        stages: [manual]

      - id: ruff-check
        name: ruff check
        entry: mise exec -- uv run --no-sync ruff check --fix
        language: system
        types: [python]

      - id: ruff-format
        name: ruff format
        entry: mise exec -- uv run --no-sync ruff format
        language: system
        types: [python]
```

### 6.5. ä¸»ãªãƒã‚§ãƒƒã‚¯ãƒ„ãƒ¼ãƒ«ã®ä¾‹

<!-- rumdl-disable MD036 -->
**gitleaks**
<!-- rumdl-enable MD036 -->

ã‚³ãƒ¼ãƒ‰å†…ã«ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ(API ã‚­ãƒ¼ã€ãƒ‘ã‚¹ãƒ¯ãƒ¼ãƒ‰ã€ãƒˆãƒ¼ã‚¯ãƒ³ãªã©)ã‚’æ¤œå‡ºã—ã¾ã™ã€‚

é˜²ã’ã‚‹äº‹æ•…ã®ä¾‹

- AI ãŒã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ç”Ÿæˆã—ãŸã¨ãã€API ã‚­ãƒ¼ã£ã½ã„æ–‡å­—åˆ—ãŒå«ã¾ã‚Œã¦ã„ãŸ
- ç’°å¢ƒå¤‰æ•°ã‚’ã‚³ãƒ”ãƒšã—ãŸã¨ãã€ã†ã£ã‹ã‚Šæœ¬ç•ªã®èªè¨¼æƒ…å ±ãŒæ··å…¥

<!-- rumdl-disable MD036 -->
**ruff**
<!-- rumdl-enable MD036 -->

Python ã‚³ãƒ¼ãƒ‰ã® lint ã¨ format ã‚’é«˜é€Ÿã«å®Ÿè¡Œã—ã¾ã™ã€‚

<!-- rumdl-disable MD036 -->
**actionlint / zizmor / pinact**
<!-- rumdl-enable MD036 -->

GitHub Actions ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®ãƒªã‚¹ã‚¯è»½æ¸›ã«å½¹ç«‹ã¡ã¾ã™ã€‚
å…¥ã‚Œã‚Œã°å…¥ã‚Œã‚‹ã»ã©å®‰å¿ƒã ã¨æ€ã„ã¾ã™ã€‚

### 6.6. GitHub Actions ã§ã®å®Ÿè¡Œ

```yaml:.github/workflows/pre-commit.yaml
name: pre-commit

on:
  pull_request:
    branches:
      - main

jobs:
  pre-commit:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install mise
        uses: jdx/mise-action@v2
        with:
          install_args: --yes
          cache: true

      - name: Cache pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: pre-commit-${{ hashFiles('.pre-commit-config.yaml') }}

      - name: Run pre-commit
        run: mise exec -- pre-commit run --all-files
```

å®Ÿéš›ã®é‹ç”¨ã§ã¯ pinact ç­‰ã‚’ä½¿ã£ã¦ SHA å›ºå®šã™ã‚‹ã“ã¨ã‚’æ¨å¥¨ã—ã¾ã™ã€‚

### 6.7. CI ã§ã®ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ

pre-commit ã«ã‚ˆã‚‹ lint ã«åŠ ãˆã¦ã€ãƒ†ã‚¹ãƒˆã‚‚ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«ã¨ã—ã¦è¿½åŠ ã§ãã¾ã™ã€‚
åˆ¥ã‚¸ãƒ§ãƒ–ã¨ã—ã¦å®šç¾©ã—ã€é›†ç´„ã‚¸ãƒ§ãƒ–ã§ã¾ã¨ã‚ã¦ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«ã§å¿…é ˆã«ã—ã¾ã™ã€‚

```yaml
  test:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    permissions:
      contents: read

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install mise
        uses: jdx/mise-action@v2
        with:
          install_args: --yes
          cache: true

      - name: Run tests
        run: mise exec -- uv run pytest

  # é›†ç´„ã‚¸ãƒ§ãƒ–: ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«ã§ã¯ã“ã®ã‚¸ãƒ§ãƒ–ã‚’å¿…é ˆã«è¨­å®š
  # matrix ã§ã‚¸ãƒ§ãƒ–ãŒå¢—æ¸›ã—ã¦ã‚‚è¨­å®šå¤‰æ›´ãŒä¸è¦ã«ãªã‚‹
  ci:
    needs: [pre-commit, test]
    if: always()
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - name: Check results
        run: |
          if [[ "${{ contains(needs.*.result, 'failure') }}" == "true" ]]; then
            echo "One or more jobs failed"
            exit 1
          fi
          if [[ "${{ contains(needs.*.result, 'cancelled') }}" == "true" ]]; then
            echo "One or more jobs were cancelled"
            exit 1
          fi
          echo "All checks passed"
```

ãƒã‚¤ãƒ³ãƒˆ

- pre-commit ã«ã¯ lint/format ã‚’å…¥ã‚Œã¦ãŠã
- CI ã§ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã€PR ãƒãƒ¼ã‚¸å‰ã«å“è³ªã‚’æ‹…ä¿
- é›†ç´„ã‚¸ãƒ§ãƒ– (ci) ã‚’ãƒ–ãƒ©ãƒ³ãƒä¿è­·ãƒ«ãƒ¼ãƒ«ã§å¿…é ˆã«ã™ã‚‹ã¨ã€lint ã¨ãƒ†ã‚¹ãƒˆä¸¡æ–¹ã®æˆåŠŸãŒå¿…é ˆã«ãªã‚‹
- æ”¹å–„ç­–2 (Skinny Notebook Wrapper + Pure Python) ã§ãƒ­ã‚¸ãƒƒã‚¯ã‚’ `.py` ã«åˆ‡ã‚Šå‡ºã—ã¦ãŠã‘ã°ãƒ†ã‚¹ãƒˆãŒæ›¸ãã‚„ã™ã„

### 6.8. ãƒ¡ãƒªãƒƒãƒˆ

1. AI ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®å“è³ªæ‹…ä¿
   - ã‚³ãƒŸãƒƒãƒˆå‰ã«è‡ªå‹•ãƒã‚§ãƒƒã‚¯
   - å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ãŒãƒªãƒã‚¸ãƒˆãƒªã«å…¥ã‚‰ãªã„
2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®è»½æ¸›
   - ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆã®æ¤œå‡º
   - æ—¢çŸ¥ã®è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
3. ãƒãƒ¼ãƒ å…¨ä½“ã§ã®å“è³ªçµ±ä¸€
   - èª°ãŒæ›¸ã„ãŸã‚³ãƒ¼ãƒ‰ã§ã‚‚åŒã˜ãƒ«ãƒ¼ãƒ«ã‚’é©ç”¨
   - AI ãƒ„ãƒ¼ãƒ«ãŒç”Ÿæˆã—ãŸã‚³ãƒ¼ãƒ‰ã‚‚ä¾‹å¤–ãªã—

## 7. ã¾ã¨ã‚

æœ¬è¨˜äº‹ã§ã¯ Databricks Notebook é–‹ç™ºç’°å¢ƒã‚’ AI-Ready ã«ã™ã‚‹ãŸã‚ã® 4 ã¤ã®æ”¹å–„ç­–ã‚’ç´¹ä»‹ã—ã¾ã—ãŸã€‚

| æ”¹å–„ç­–                                | è§£æ±ºã™ã‚‹èª²é¡Œ                                |
| --------                              | ------------                                |
| jupyter-databricks-kernel             | ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºç’°å¢ƒã¨ã®ä¹–é›¢ã€AI ãƒ„ãƒ¼ãƒ«ã¨ã®é€£æº |
| Skinny Notebook Wrapper + Pure Python | ã‚³ãƒ¼ãƒ‰å“è³ªç®¡ç†ã€ãƒ†ã‚¹ã‚¿ãƒ“ãƒªãƒ†ã‚£              |
| uv ã«ã‚ˆã‚‹ä¾å­˜é–¢ä¿‚ç®¡ç†                 | ä¾å­˜é–¢ä¿‚ã®è¤‡é›‘ã•ã€å†ç¾æ€§                    |
| ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«                          | AI ç”Ÿæˆã‚³ãƒ¼ãƒ‰ã®å“è³ªãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£           |

AI ãƒ„ãƒ¼ãƒ«ã¯å¼·åŠ›ã§ã™ãŒã€ãã‚Œã‚’æœ€å¤§é™æ´»ç”¨ã™ã‚‹ãŸã‚ã«ã¯é–‹ç™ºç’°å¢ƒã®æ•´å‚™ãŒæ¬ ã‹ã›ã¾ã›ã‚“ã€‚
æœ¬è¨˜äº‹ã§ç´¹ä»‹ã—ãŸæ”¹å–„ç­–ã‚’å‚è€ƒã«ã€çš†ã•ã‚“ã® Databricks é–‹ç™ºç’°å¢ƒã‚‚ AI-Ready ã«ã—ã¦ã„ãŸã ã‘ã‚Œã°å¹¸ã„ã§ã™ã€‚

## 8. é–¢é€£è¨˜äº‹

å„ãƒˆãƒ”ãƒƒã‚¯ã®è©³ç´°ã¯ä»¥ä¸‹ã®è¨˜äº‹ã§è§£èª¬ã—ã¦ã„ã¾ã™ã€‚

@[card](https://zenn.dev/genda_jp/articles/2025-12-10-organize-databricks-notebook-management)

@[card](https://zenn.dev/genda_jp/articles/2025-12-11-use-uv-in-databricks)

@[card](https://zenn.dev/genda_jp/articles/2025-12-06-ai-guardrails-local-cloud)

## 9. å‚è€ƒãƒªãƒ³ã‚¯

- [jupyter-databricks-kernel (GitHub)](https://github.com/i9wa4/jupyter-databricks-kernel)
- [uv Documentation](https://docs.astral.sh/uv/)
- [mise Documentation](https://mise.jdx.dev/)
- [pre-commit Documentation](https://pre-commit.com/)
