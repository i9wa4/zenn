---
title: "Databricks ã§ uv ã‚’æ´»ç”¨ã—ã¦ä¾å­˜é–¢ä¿‚ã‚’ç®¡ç†ã™ã‚‹"
emoji: "ğŸ´"
type: "tech"
topics:
  - "databricks"
  - "python"
  - "uv"
publication_name: "genda_jp"
published: true
published_at: 2025-12-11 07:00
---

## 1. ã¯ã˜ã‚ã«

æ ªå¼ä¼šç¤¾GENDA ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ / MLOps ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã® uma-chan ã§ã™ã€‚
ã“ã®è¨˜äº‹ã¯ GENDA Advent Calendar 2025 ã‚·ãƒªãƒ¼ã‚º4 Day 11 ã®è¨˜äº‹ã§ã™ã€‚

@[card](https://qiita.com/advent-calendar/2025/genda)

æœ¬è¨˜äº‹ã§ã¯ã€Databricks ã§ uv ã‚’ä½¿ã£ã¦ä¾å­˜é–¢ä¿‚ã‚’ç®¡ç†ã™ã‚‹æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

## 2. uv ã¨ã¯

uv ã¯ Rust è£½ã®é«˜é€Ÿãª Python ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ã§ã™ã€‚

@[card](https://docs.astral.sh/uv/)

ä¸»ãªç‰¹å¾´

- pip ã®10-100å€é«˜é€Ÿ
- `uv.lock` ã«ã‚ˆã‚‹å†ç¾å¯èƒ½ãªä¾å­˜é–¢ä¿‚ç®¡ç†
- Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã‚‚å¯èƒ½

## 3. Databricks ã§ã®ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†æ–¹æ³•

æœ¬è¨˜äº‹ã§ã¯3ã¤ã®æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚

| æ–¹æ³•                      | æ¦‚è¦                       | ãŠã™ã™ã‚åº¦   |
| ------                    | ------                     | ------------ |
| uv sync --active          | ãƒ­ãƒ¼ã‚«ãƒ«ã¨åŒã˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ | â˜…â˜…â˜…       |
| requirements.txt äº‹å‰ç”Ÿæˆ | PR ã§å·®åˆ†ç¢ºèªå¯èƒ½          | â˜…â˜…â˜†       |
| requirements.txt å‹•çš„ç”Ÿæˆ | ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ä¸è¦           | â˜…â˜†â˜†       |

### 3.1. uv sync --active (ãŠã™ã™ã‚)

`--active` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã‚’ä½¿ã†ã¨ã€Databricks ã®æ—¢å­˜ç’°å¢ƒã«ç›´æ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã§ãã¾ã™ã€‚

```python
%pip install uv
```

```python
import subprocess

result = subprocess.run(
    ["uv", "sync", "--no-dev", "--active"],
    capture_output=True,
    text=True
)
```

`--active` ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã¯ã€æ–°ã—ã„ `.venv` ã‚’ä½œæˆã›ãšã€
ç¾åœ¨ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãªä»®æƒ³ç’°å¢ƒ (`VIRTUAL_ENV` ç’°å¢ƒå¤‰æ•°ã§æŒ‡å®šã•ã‚ŒãŸç’°å¢ƒ) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

Databricks ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç’°å¢ƒã§ã¯ã€æ—¢ã« `/local_disk0/` ä¸Šã«
ä»®æƒ³ç’°å¢ƒãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ã¦ã„ã‚‹ãŸã‚ã€
`/Workspace` ä¸Šã« `.venv` ã‚’ä½œæˆã™ã‚‹éš›ã®å•é¡Œã‚’å›é¿ã§ãã¾ã™ã€‚

ãƒ¡ãƒªãƒƒãƒˆ

- ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºã¨åŒã˜ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼
- `uv.lock` ã‹ã‚‰ç›´æ¥ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãŸã‚æ•´åˆæ€§ãŒä¿è¨¼ã•ã‚Œã‚‹

ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ

- æ¯å› uv ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒç™ºç”Ÿã™ã‚‹

#### 3.1.1. æ³¨æ„ç‚¹

- Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®æ•´åˆæ€§
    - `requires-python` ã‚’ DBR ã® Python ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã«åˆã‚ã›ã‚‹
    - ä¾‹: DBR 17.3 LTS ã¯ Python 3.12.3
- DBR ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã®ç«¶åˆ
    - `dependencies` ã«ã¯ DBR ã«ãªã„ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã¿è¨˜è¼‰ã™ã‚‹
    - pandas, numpy ç­‰ã¯ DBR ã«ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿

### 3.2. requirements.txt äº‹å‰ç”Ÿæˆ

`uv.lock` ã‹ã‚‰ `requirements.txt` ã‚’ç”Ÿæˆã—ã€ãƒªãƒã‚¸ãƒˆãƒªã«ã‚³ãƒŸãƒƒãƒˆã—ã¦ãŠãã¾ã™ã€‚

```bash
uv export --no-hashes --no-dev > requirements.txt
```

Databricks ã§ã¯äº‹å‰ç”Ÿæˆã—ãŸ requirements.txt ã‚’ä½¿ã„ã¾ã™ã€‚

```python
%pip install -r requirements.txt
```

pre-commit ã§è‡ªå‹•åŒ–ã™ã‚‹ã¨ã€ç”Ÿæˆå¿˜ã‚Œã‚„æ‰‹å‹•ç·¨é›†ã«ã‚ˆã‚‹æ•´åˆæ€§ã‚¨ãƒ©ãƒ¼ã‚’é˜²ã’ã¾ã™ã€‚

```yaml
# .pre-commit-config.yaml
repos:
  - repo: local
    hooks:
      - id: uv-export
        name: uv export
        entry: uv export --no-hashes --no-dev -o requirements.txt
        language: system
        files: ^(pyproject\.toml|uv\.lock)$
        pass_filenames: false
```

ãƒ¡ãƒªãƒƒãƒˆ

- PR ã§ä¾å­˜é–¢ä¿‚ã®å¤‰æ›´ãŒè¦‹ã‚„ã™ã„
- uv ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ãŒä¸è¦

ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ

- requirements.txt ã®ç”Ÿæˆå¿˜ã‚Œãƒªã‚¹ã‚¯

### 3.3. requirements.txt å‹•çš„ç”Ÿæˆ

uv ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãŠãå‹•çš„ç”Ÿæˆã™ã‚‹ã“ã¨ã‚‚å¯èƒ½ã§ã™ã€‚

```python
%pip install uv
```

```python
import subprocess
result = subprocess.run(
    ["uv", "export", "--no-hashes", "--no-dev"],
    cwd="/Workspace/Repos/<user>/<repo>",
    capture_output=True,
    text=True
)
print(result.stdout)
```

ãã‚‚ãã‚‚ `uv sync --active` ãŒå‹•ãã®ã§ã‚ã‚Œã°ç‰¹ã«ã“ã®æ–¹æ³•ã‚’é¸ã¶åˆ©ç‚¹ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚

## 4. pyproject.toml ã®æ§‹æˆ

```toml
[project]
name = "databricks-project"
version = "0.1.0"
requires-python = ">=3.12"
dependencies = [
    # Databricks ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
]

[dependency-groups]
dev = [
    "pytest",
    "ruff",
]
dbr = [
    # DBR 17.3 LTS ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿
    # https://docs.databricks.com/aws/en/release-notes/runtime/17.3lts
    "pandas==2.2.3",
    "numpy==2.1.3",
    "pyspark==4.0.0",
]
```

ãƒã‚¤ãƒ³ãƒˆ

- `dependencies`: Databricks ã«ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã™ã‚‹ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
- `dev`: ãƒ­ãƒ¼ã‚«ãƒ«é–‹ç™ºãƒ„ãƒ¼ãƒ«
- `dbr`: Databricks Runtime (DBR) ãƒ—ãƒªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
    - ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•´åˆæ€§ã‚’ä¿ã¤ãŸã‚ã«è¨˜è¼‰
    - `uv export --no-dev` ã§ã‚‚å«ã¾ã‚Œãªã„ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é™¤å¤–)

## 5. ã¾ã¨ã‚

uv ã‚’ä½¿ã†ã“ã¨ã§ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ä¾å­˜é–¢ä¿‚ã‚’åŠ¹ç‡çš„ã«ç®¡ç†ã§ãã¾ã™ã€‚

ã¾ã  uv ã‚’ä½¿ã£ãŸã“ã¨ãŒãªã„å ´åˆã¯ãœã²è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚

## 6. é–¢é€£è¨˜äº‹

@[card](https://zenn.dev/genda_jp/articles/2025-12-10-organize-databricks-notebook-management)

@[card](https://zenn.dev/genda_jp/articles/2025-12-06-ai-guardrails-local-cloud)

## 7. å‚è€ƒ

- <https://docs.astral.sh/uv/>
- <https://docs.astral.sh/uv/reference/cli/#uv-export>
