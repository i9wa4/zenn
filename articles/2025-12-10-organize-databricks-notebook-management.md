---
title: "ã‚«ã‚ªã‚¹åŒ–ã‚’é˜²ãDatabricksã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç®¡ç†æ–¹æ³•"
emoji: "ğŸ““"
type: "tech"
topics:
  - "databricks"
  - "jupyter"
  - "python"
  - "ruff"
publication_name: "genda_jp"
published: false
---

## 1. ã¯ã˜ã‚ã«

æ ªå¼ä¼šç¤¾GENDA ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ / MLOps ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã® uma-chan ã§ã™ã€‚
ã“ã®è¨˜äº‹ã¯ GENDA Advent Calendar 2025 ã‚·ãƒªãƒ¼ã‚º4 Day 10 ã®è¨˜äº‹ã§ã™ã€‚

@[card](https://qiita.com/advent-calendar/2025/genda)

Databricks ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã® Git diff ãŒèª­ã‚ãªã„ã€ãƒ†ã‚¹ãƒˆãŒæ›¸ã‘ãªã„ã€
ãã‚“ãªæ‚©ã¿ã‚’æŠ±ãˆã¦ã„ã¾ã›ã‚“ã‹ï¼Ÿ

æœ¬è¨˜äº‹ã§ã¯ã€2ã¤ã®è§£æ±ºç­–ã‚’æ®µéšçš„ã«ç´¹ä»‹ã—ã¾ã™ã€‚

1. **Sourceå½¢å¼** - ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ `.py` å½¢å¼ã§ä¿å­˜
2. **Thin Notebook Wrapper** - ãƒ­ã‚¸ãƒƒã‚¯ã‚’åˆ¥ãƒ•ã‚¡ã‚¤ãƒ«ã«åˆ†é›¢

ã¾ãšã¯ Sourceå½¢å¼ã‚’è©¦ã—ã€ãã‚Œã§ã‚‚è¶³ã‚Šãªã„å ´åˆã«
Thin Notebook Wrapper ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œè¨ã—ã¦ãã ã•ã„ã€‚

## 2. å¾“æ¥ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯é–‹ç™ºã®èª²é¡Œ

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã® IPYNBå½¢å¼ï¼ˆ`.ipynb`ï¼‰ã¯ JSON ãƒ™ãƒ¼ã‚¹ã®ãŸã‚ã€
é€šå¸¸ã®é–‹ç™ºãƒ„ãƒ¼ãƒ«ãŒä½¿ã„ã«ãã„ã§ã™ã€‚

| é …ç›® | IPYNBå½¢å¼ | ç†æƒ³ |
|------|-----------|------|
| Git diff | JSON ã§èª­ã¿ã«ãã„ | ãƒ†ã‚­ã‚¹ãƒˆã§èª­ã¿ãŸã„ |
| pytest | å®Ÿè¡Œå›°é›£ | ç°¡å˜ã«ãƒ†ã‚¹ãƒˆã—ãŸã„ |
| IDE è£œå®Œ | åŠ¹ãã«ãã„ | å®Œå…¨ã«åŠ¹ã‹ã›ãŸã„ |

â€» Ruffï¼ˆLinter/Formatterï¼‰ã¯ `.ipynb` ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚

## 3. è§£æ±ºç­–1: Sourceå½¢å¼

### 3.1. Sourceå½¢å¼ã¨ã¯

Databricks ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ IPYNBå½¢å¼ä»¥å¤–ã« **Sourceå½¢å¼** ã‚’ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã¾ã™ã€‚
Sourceå½¢å¼ã§ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒ `.py`ï¼ˆã¾ãŸã¯ `.scala`, `.sql`, `.r`ï¼‰ãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜ã•ã‚Œã¾ã™ã€‚

```python
# Databricks notebook source
# MAGIC %md
# MAGIC # ã‚µãƒ³ãƒ—ãƒ«ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

# COMMAND ----------

print("Hello, Databricks!")

# COMMAND ----------

df = spark.table("samples.nyctaxi.trips")
df.show()
```

ãƒ•ã‚¡ã‚¤ãƒ«å…ˆé ­ã® `# Databricks notebook source` ã‚³ãƒ¡ãƒ³ãƒˆã«ã‚ˆã‚Šã€
Databricks ãŒã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ã—ã¦èªè­˜ã—ã¾ã™ã€‚

### 3.2. IPYNBå½¢å¼ vs Sourceå½¢å¼

| é …ç›® | IPYNBå½¢å¼ | Sourceå½¢å¼ |
|------|-----------|------------|
| ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ | JSONï¼ˆ`.ipynb`ï¼‰ | ãƒ†ã‚­ã‚¹ãƒˆï¼ˆ`.py`ç­‰ï¼‰ |
| Git diff | èª­ã¿ã«ãã„ | èª­ã¿ã‚„ã™ã„ |
| å‡ºåŠ›ã®ä¿å­˜ | å¯èƒ½ | ä¸å¯ |
| Ruff å¯¾å¿œ | ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆ | é€šå¸¸ã® `.py` ã¨ã—ã¦å¯¾å¿œ |

### 3.3. Sourceå½¢å¼ã¸ã®å¤‰æ›´æ–¹æ³•

**å€‹åˆ¥ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯:**
File ãƒ¡ãƒ‹ãƒ¥ãƒ¼ â†’ Notebook format â†’ Source ã‚’é¸æŠ

**ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š:**
Settings â†’ Developer â†’ Editor settings ã§å¤‰æ›´

æ³¨æ„: IPYNBå½¢å¼ã‹ã‚‰ Sourceå½¢å¼ã«å¤‰æ›ã™ã‚‹ã¨ã€ã‚»ãƒ«ã®å‡ºåŠ›ï¼ˆå®Ÿè¡Œçµæœï¼‰ã¯å¤±ã‚ã‚Œã¾ã™ã€‚

### 3.4. Sourceå½¢å¼ã®é™ç•Œ

Sourceå½¢å¼ã§ Git diff ã®å•é¡Œã¯è§£æ±ºã—ã¾ã™ãŒã€ä»¥ä¸‹ã¯æ®‹ã‚Šã¾ã™ã€‚

- ãƒ­ã‚¸ãƒƒã‚¯ãŒã‚»ãƒ«ã«æ•£ã‚‰ã°ã‚‹å•é¡Œ
- `dbutils` / `spark` ä¾å­˜ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆå›°é›£
- ã‚³ãƒ¼ãƒ‰ã®å†åˆ©ç”¨æ€§

ã“ã‚Œã‚‰ã‚’è§£æ±ºã™ã‚‹ã«ã¯ã€æ¬¡ã® Thin Notebook Wrapper ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæœ‰åŠ¹ã§ã™ã€‚

## 4. è§£æ±ºç­–2: Thin Notebook Wrapper ãƒ‘ã‚¿ãƒ¼ãƒ³

### 4.1. åŸºæœ¬çš„ãªè€ƒãˆæ–¹

**Thin Notebook Wrapper** ã¨ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’ã€Œè–„ã„ãƒ©ãƒƒãƒ‘ãƒ¼ã€ã¨ã—ã¦æ‰±ã„ã€
å®Ÿéš›ã®ãƒ­ã‚¸ãƒƒã‚¯ã¯ `.py` ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ããƒ‘ã‚¿ãƒ¼ãƒ³ã§ã™ã€‚
Web é–‹ç™ºã«ãŠã‘ã‚‹ã€ŒThin Controllerã€ï¼ˆã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã¯å‡¦ç†ã‚’æŒ¯ã‚Šåˆ†ã‘ã‚‹ã ã‘ã§ã€
ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã¯åˆ¥ã®ãƒ¬ã‚¤ãƒ¤ãƒ¼ã«æ›¸ãè¨­è¨ˆï¼‰ã¨åŒã˜è€ƒãˆæ–¹ã§ã™ã€‚

```text
project/
â”œâ”€â”€ launcher.py       # è–„ã„ãƒ©ãƒƒãƒ‘ãƒ¼ï¼ˆSourceå½¢å¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ï¼‰
â”œâ”€â”€ main.py           # ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆé€šå¸¸ã® Python ãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
â”œâ”€â”€ test_main.py      # ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
â””â”€â”€ pyproject.toml    # Ruff è¨­å®š
```

â€» launcher ã¯ IPYNBå½¢å¼ï¼ˆ`launcher.ipynb`ï¼‰ã§ã‚‚æ§‹ã„ã¾ã›ã‚“ã€‚

### 4.2. ãªãœãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‚’æ®‹ã™ã®ã‹

ãƒ­ã‚¸ãƒƒã‚¯ã‚’ `.py` ã«åˆ‡ã‚Šå‡ºã—ã¦ã‚‚ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ä»¥ä¸‹ã®ç†ç”±ã§ä¾¿åˆ©ã§ã™ã€‚

| å½¹å‰² | ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ | .py ãƒ•ã‚¡ã‚¤ãƒ« |
|------|-------------|--------------|
| Widget ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | â—‹ | Ã— |
| Databricks UI ã§ã®ãƒ‡ãƒãƒƒã‚° | â—‹ | Ã— |
| ãƒ†ã‚¹ãƒˆ | Ã— | â—‹ |

Databricks Job ã§ã¯ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ Notebook Taskã€`.py` ãƒ•ã‚¡ã‚¤ãƒ«ã¯ `spark_python_task` ã§å®Ÿè¡Œã§ãã¾ã™ã€‚
ãŸã ã— Widget ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¯ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã®ã¿ä½¿ãˆã¾ã™ã€‚

ã¤ã¾ã‚Šã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€ŒJob ã®ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆã€ã¨ã—ã¦æ®‹ã—ã¤ã¤ã€
ãƒ­ã‚¸ãƒƒã‚¯ã¯ `.py` ã«æ›¸ãã®ãŒãƒ™ã‚¹ãƒˆã§ã™ã€‚

### 4.3. launcher ã¯ãŸã£ãŸ2ã‚»ãƒ«

Databricks Repos / Git Folders ã‚’ä½¿ã†å ´åˆã®ä¾‹ã§ã™ã€‚
ï¼ˆWorkspace Files ã®å ´åˆã¯ `sys.path` è¨­å®šãŒå¿…è¦ã€‚è©³ç´°ã¯ã‚»ã‚¯ã‚·ãƒ§ãƒ³6å‚ç…§ï¼‰

```python
# Cell 1: Widgetå®šç¾©
dbutils.widgets.text("table_name", "samples.nyctaxi.trips", "Table Name")
dbutils.widgets.text("limit", "10", "Limit")
```

```python
# Cell 2: main() å®Ÿè¡Œ
from main import main

# Widget ã¯æ–‡å­—åˆ—ã‚’è¿”ã™ãŸã‚ã€å¿…è¦ã«å¿œã˜ã¦å‹å¤‰æ›
main(
    table_name=dbutils.widgets.get("table_name"),
    limit=int(dbutils.widgets.get("limit")),
)
```

ãƒã‚¤ãƒ³ãƒˆ:

- `dbutils` ã¯ Databricks ãŒäº‹å‰å®šç¾©ï¼ˆå†ç”Ÿæˆä¸è¦ï¼‰
- Ruff ã® F821 ã‚¨ãƒ©ãƒ¼ã¯ `pyproject.toml` ã§æŠ‘åˆ¶ï¼ˆã‚»ã‚¯ã‚·ãƒ§ãƒ³5å‚ç…§ï¼‰
- ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¯ã€Œèµ·å‹•è£…ç½®ã€ã«å¾¹ã™ã‚‹

Databricks Job ã®è¨­å®šã§ `base_parameters` ã‚’æŒ‡å®šã™ã‚‹ã¨ã€
Widget ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ä¸Šæ›¸ãã§ãã¾ã™ã€‚

```json
{
  "notebook_task": {
    "notebook_path": "/path/to/launcher",
    "base_parameters": {
      "table_name": "production.sales.orders",
      "limit": "1000"
    }
  }
}
```

### 4.4. main.py ã«ãƒ­ã‚¸ãƒƒã‚¯ã‚’é›†ç´„

```python
"""ãƒ¡ã‚¤ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""

from pyspark.sql import DataFrame, SparkSession


def load_table(spark: SparkSession, table_name: str, limit: int) -> DataFrame:
    """ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    return spark.table(table_name).limit(limit)


def main(table_name: str, limit: int = 10) -> None:
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼ˆãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰å‘¼ã°ã‚Œã‚‹ï¼‰"""
    spark = SparkSession.builder.getOrCreate()
    df = load_table(spark, table_name, limit)
    df.show()
```

ãƒã‚¤ãƒ³ãƒˆ:

- `load_table()` ã¯ `spark` ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ãŸã‚ãƒ¢ãƒƒã‚¯å¯èƒ½
- `dbutils` ã«ä¾å­˜ã—ãªã„
- å‹ã‚¢ãƒãƒ†ãƒ¼ã‚·ãƒ§ãƒ³ä»˜ãã§ IDE è£œå®ŒãŒåŠ¹ã

### 4.5. ãƒ†ã‚¹ãƒˆã®ä¾‹

`load_table()` ã¯ `spark` ã‚’å¼•æ•°ã§å—ã‘å–ã‚‹ãŸã‚ã€ãƒ¢ãƒƒã‚¯ã‚’ä½¿ã£ã¦ãƒ†ã‚¹ãƒˆã§ãã¾ã™ã€‚

```python
# test_main.py
from unittest.mock import MagicMock

from main import load_table


def test_load_table():
    mock_spark = MagicMock()
    mock_df = MagicMock()
    mock_spark.table.return_value.limit.return_value = mock_df

    result = load_table(mock_spark, "test_table", 10)

    mock_spark.table.assert_called_once_with("test_table")
    mock_spark.table.return_value.limit.assert_called_once_with(10)
    assert result == mock_df
```

ã“ã®ãƒ†ã‚¹ãƒˆã¯ Databricks ç’°å¢ƒãŒãªãã¦ã‚‚å®Ÿè¡Œã§ãã¾ã™ã€‚

```bash
# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
pytest test_main.py
```

## 5. Ruffï¼ˆLinter/Formatterï¼‰ã®è¨­å®š

Ruff ã¯ Rust è£½ã®é«˜é€Ÿãª Python Linter/Formatter ã§ã™ã€‚

### 5.1. F821 ã‚¨ãƒ©ãƒ¼ã‚’ pyproject.toml ã§æŠ‘åˆ¶

ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯å†…ã§ `dbutils` ã‚„ `spark` ã‚’ä½¿ã†ã¨
Ruff ãŒ F821 (Undefined name) ã‚¨ãƒ©ãƒ¼ã‚’å‡ºã—ã¾ã™ã€‚

```text
F821 Undefined name `dbutils`
F821 Undefined name `spark`
```

Databricks ç’°å¢ƒã§ã¯ `spark` ã¨ `dbutils` ãŒäº‹å‰å®šç¾©ã•ã‚Œã¦ã„ã¾ã™ãŒã€
Ruff ã¯é™çš„è§£æãƒ„ãƒ¼ãƒ«ãªã®ã§ã“ã‚Œã‚’èªè­˜ã§ãã¾ã›ã‚“ã€‚
`per-file-ignores` ã§ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ã¿ F821 ã‚’ç„¡è¦–ã—ã¾ã™ã€‚

### 5.2. pyproject.toml ã®è¨­å®šä¾‹

```toml
[tool.ruff]
line-length = 88
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # Pyflakes
    "I",   # isort
    "B",   # flake8-bugbear
    "UP",  # pyupgrade
]

[tool.ruff.lint.per-file-ignores]
# IPYNBå½¢å¼ã®å ´åˆï¼ˆå…¨ã¦ã® .ipynb ã«é©ç”¨ï¼‰
"*.ipynb" = ["F821"]
# Sourceå½¢å¼ã®å ´åˆï¼ˆãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ç”¨ .py ã®ã¿æŒ‡å®šã€‚é€šå¸¸ã® .py ã«ã¯é©ç”¨ã—ãªã„ï¼‰
"launcher.py" = ["F821"]
```

Ruff ã¯ `.ipynb` ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ãŸã‚ã€
IPYNBå½¢å¼ã§ã‚‚ Sourceå½¢å¼ã§ã‚‚åŒã˜ãƒ«ãƒ¼ãƒ«ã§ãƒã‚§ãƒƒã‚¯ã§ãã¾ã™ã€‚

```bash
# .py ã‚‚ .ipynb ã‚‚ä¸¡æ–¹ãƒã‚§ãƒƒã‚¯
ruff check .
```

## 6. .py ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

### 6.1. Databricks Repos / Git Folders ã‚’ä½¿ã†

Databricks Reposï¼ˆç¾åœ¨ã¯ Git Folders ã¨å‘¼ã°ã‚Œã¦ã„ã¾ã™ï¼‰ã‚’ä½¿ã†ã¨ã€
ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè‡ªå‹•çš„ã« `sys.path` ã«å«ã¾ã‚Œã¾ã™ã€‚

```text
/Repos/your-name/project/
â”œâ”€â”€ launcher.py   # Sourceå½¢å¼ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯
â”œâ”€â”€ main.py
â””â”€â”€ utils.py
```

ã“ã®æ§‹æˆãªã‚‰ã€ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã‹ã‚‰ `from main import main` ãŒ
è¿½åŠ è¨­å®šãªã—ã§å‹•ä½œã—ã¾ã™ã€‚

â€» ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ `.py` ãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹ãƒ•ãƒ©ãƒƒãƒˆæ§‹æˆã‚’å‰æã¨ã—ã¾ã™ã€‚

### 6.2. Workspace Files ã‚’ä½¿ã†å ´åˆ

Workspace Filesï¼ˆ`/Workspace/Users/...`ï¼‰ã‚’ä½¿ã†å ´åˆã¯ã€
ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‘ã‚¹ã‹ã‚‰ç›¸å¯¾çš„ã«ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’è¨ˆç®—ã—ã¾ã™ã€‚

```python
import os
import sys

# ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®ãƒ‘ã‚¹ã‚’å–å¾—ï¼ˆ/Workspace ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ãªã—ï¼‰
# ä¾‹: /Users/your-name/project/launcher
notebook_context = dbutils.notebook.entry_point.getDbutils().notebook().getContext()
notebook_path = notebook_context.notebookPath().get()

# /Workspace ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã‚’ä»˜ã‘ã¦ãƒ•ãƒ«ãƒ‘ã‚¹ã«å¤‰æ›
# ä¾‹: /Workspace/Users/your-name/project
PROJECT_ROOT = f"/Workspace{os.path.dirname(notebook_path)}"

if PROJECT_ROOT not in sys.path:
    sys.path.insert(0, PROJECT_ROOT)
```

æ³¨æ„: ä¸Šè¨˜ã¯ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã¨ `.py` ãƒ•ã‚¡ã‚¤ãƒ«ãŒåŒã˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ã‚ã‚‹
ãƒ•ãƒ©ãƒƒãƒˆæ§‹æˆã‚’å‰æã¨ã—ã¦ã„ã¾ã™ã€‚

## 7. ã¾ã¨ã‚

### Sourceå½¢å¼ã§è§£æ±ºã§ãã‚‹ã“ã¨

- Git diff ãŒèª­ã¿ã‚„ã™ããªã‚‹
- Ruff ã§é€šå¸¸ã® `.py` ã¨ã—ã¦ãƒã‚§ãƒƒã‚¯å¯èƒ½

### Thin Notebook Wrapper ã§è§£æ±ºã§ãã‚‹ã“ã¨

- ãƒ­ã‚¸ãƒƒã‚¯ã®åˆ†é›¢ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆå¯èƒ½æ€§
- ã‚³ãƒ¼ãƒ‰ã®å†åˆ©ç”¨æ€§å‘ä¸Š
- IDE è£œå®Œã®å®Œå…¨å‹•ä½œ

æ—¢å­˜ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ãŒã‚ã‚‹å ´åˆã¯ã€ã¾ãš Sourceå½¢å¼ã¸ã®å¤‰æ›ã‚’è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚
ãƒ†ã‚¹ãƒˆã‚„å†åˆ©ç”¨ãŒå¿…è¦ã«ãªã£ãŸã‚‰ Thin Notebook Wrapper ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å°å…¥ã—ã¾ã—ã‚‡ã†ã€‚

## 8. é–¢é€£è¨˜äº‹

ã‚¬ãƒ¼ãƒ‰ãƒ¬ãƒ¼ãƒ«æ§‹æˆï¼ˆmise + pre-commit + Renovateï¼‰ã«ã¤ã„ã¦ã¯
ä»¥ä¸‹ã®è¨˜äº‹ã§ç´¹ä»‹ã—ã¦ã„ã¾ã™ã€‚

@[card](https://zenn.dev/genda_jp/articles/2025-12-06-ai-guardrails-local-cloud)

## å‚è€ƒ

- [Manage notebook format | Databricks Documentation](https://docs.databricks.com/aws/en/notebooks/notebook-format)
